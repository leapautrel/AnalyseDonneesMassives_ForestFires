id = "mydropdown",
title = "Dropdown 1",
icon = icon("sliders"),
sliderInput(
inputId = "n",
label = "Number of observations",
min = 10, max = 100, value = 30
),
prettyToggle(
inputId = "na",
label_on = "NAs kept",
label_off = "NAs removed",
icon_on = icon("check"),
icon_off = icon("remove")
)
),
dropdownBlock(
id = "mydropdown2",
title = "Dropdown 2",
icon = icon("sliders"),
prettySwitch(
inputId = "switch4",
label = "Fill switch with status:",
fill = TRUE,
status = "primary"
),
prettyCheckboxGroup(
inputId = "checkgroup2",
label = "Click me!",
thick = TRUE,
choices = c("Click me !", "Me !", "Or me !"),
animation = "pulse",
status = "info"
)
)
),
dropdownMenu(
type = "tasks",
badgeStatus = "danger",
taskItem(value = 20, color = "aqua", "Refactor code"),
taskItem(value = 40, color = "green", "Design new layout"),
taskItem(value = 60, color = "yellow", "Another task"),
taskItem(value = 80, color = "red", "Write documentation")
)
),
sidebar = dashboardSidebar(),
body = dashboardBody(
setShadow(class = "dropdown-menu")
),
title = "DashboardPage"
),
server = function(input, output) { }
)
rm(list = ls())
library (data.table)				# Dataframe plus efficace pour donnees imposantes
library(randomForest)
# Importation des donnees ----
fires <- fread(
"D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny/data/fires.csv",
header = TRUE,
sep = ",",
na.strings = "",
blank.lines.skip = TRUE,
stringsAsFactors = TRUE
)
# Sélection des feux de cause connue pour les années qui nous intéressent ----
fires_selec <-
fires[stat_cause_descr != "Missing/Undefined" &
fire_year %in% c(1995, 2000, 2005, 2010, 2015), ]
fires_selec$fire_year <- factor(fires_selec$fire_year)
fires_selec$stat_cause_descr <- factor(fires_selec$stat_cause_descr)
# Création des tableaux train et test ----
set.seed(123)
train_index <- sample(c(TRUE, FALSE),
nrow(fires_selec),
replace = TRUE,
prob = c(0.8, 0.2))
test_index <- !train_index
data_train <- as.data.table(fires_selec[train_index, c(1:4, 6)])
data_test <- as.data.table(fires_selec[test_index, c(1:4, 6)])
print(object.size(data_train), units = 'Mb')
# On initalise les vecteurs
ntree <- c(1, 5, 10, 25, 50)
accuracy <- rep(0, 5)
syst_time <- rep(0, 5)
# 1 tree
mod_rf_1 <- randomForest(stat_cause_descr ~ .,
ntree = 1,
data = data_train)
p_rf_1 <- predict(mod_rf_1,
newdata = data_test,
type = "response")
cM_1 <- caret::confusionMatrix(factor(p_rf_1,
levels = levels(data_test$stat_cause_descr)),
reference = data_test$stat_cause_descr)
accuracy[1] <- cM_1$overall["Accuracy"]
syst_time[1] <- system.time(randomForest(stat_cause_descr ~ .,
ntree = 1,
data = data_train))[3]
# 5 trees
mod_rf_5 <- randomForest(stat_cause_descr ~ .,
ntree = 5,
data = data_train)
p_rf_5 <- predict(mod_rf_5,
newdata = data_test,
type = "response")
cM_5 <- caret::confusionMatrix(factor(p_rf_5,
levels = levels(data_test$stat_cause_descr)),
reference = data_test$stat_cause_descr)
accuracy[2] <- cM_5$overall["Accuracy"]
syst_time[2] <- system.time(randomForest(stat_cause_descr ~ .,
ntree = 5,
data = data_train))[3]
# 10 trees
mod_rf_10 <- randomForest(stat_cause_descr ~ .,
ntree = 10,
data = data_train)
p_rf_10 <- predict(mod_rf_10,
newdata = data_test,
type = "response")
cM_10 <- caret::confusionMatrix(factor(p_rf_10,
levels = levels(data_test$stat_cause_descr)),
reference = data_test$stat_cause_descr)
accuracy[3] <- cM_10$overall["Accuracy"]
syst_time[3] <- system.time(randomForest(stat_cause_descr ~ .,
ntree = 10,
data = data_train))[3]
data_plot <- data.frame(ntree = ntree,
accuracy = accuracy,
syst_time = syst_time)
data_plot <- data.frame(ntree = ntree,
accuracy = accuracy,
syst_time = syst_time)
plot <- ggplot(data_plot, aes(x = ntree, y = accuracy)) +
geom_line(aes(color = variable)) +
facet_grid(variable ~ ., scales = "free_y") +
theme(legend.position = "none")
library(ggplot2)
plot <- ggplot(data_plot, aes(x = ntree, y = accuracy)) +
geom_line(aes(color = variable)) +
facet_grid(variable ~ ., scales = "free_y") +
theme(legend.position = "none")
plot
# Graphique
ggplot() +
geom_line(mapping = aes(x = ntree, y = accuracy))
plot <- ggplot(data_plot, aes(x = ntree, y = accuracy)) +
geom_line(aes(color = variable)) +
facet_grid(syst_time ~ .) +
theme_minimal() +
theme(legend.position = "none")
plot
plot <- ggplot(data_plot, aes(x = ntree, y = accuracy)) +
facet_grid(syst_time ~ .) +
theme_minimal() +
theme(legend.position = "none")
plot
# Graphique
ggplot() +
geom_line(mapping = aes(x = ntree, y = accuracy)) +
theme_minimal()
ggplot() +
geom_line(mapping = aes(x = ntree, y = syst_time)) +
theme_minimal()
vec_ntree <- c(1, 5)
# Version fonction
rf_ntrees <- function(ntree) {
mod_rf <- randomForest(stat_cause_descr ~ .,
ntree = ntree,
data = data_train)
p_rf <- predict(mod_rf,
newdata = data_test,
type = "response")
cM <- caret::confusionMatrix(factor(p_rf,
levels = levels(data_test$stat_cause_descr)),
reference = data_test$stat_cause_descr)
accuracy <- cM$overall["Accuracy"]
syst_time <- system.time(randomForest(stat_cause_descr ~ .,
ntree = ntree,
data = data_train))[3]
}
vec_ntree <- c(1, 5)
res <- apply(vec_ntree, fun)
?apply
res <- apply(X = vec_ntree, FUN = rf_ntrees)
vec_ntree <- c(1, 5)
res <- apply(X = vec_ntree, FUN = rf_ntrees)
res <- apply(vec_ntree, FUN = rf_ntrees)
vec_ntree <- c(1, 5)
res <- apply(vec_ntree, FUN = rf_ntrees)
res <- lapply(vec_ntree, FUN = rf_ntrees)
list(accuracy = accuracy, syst_time = syst_time)
# Version fonction
rf_ntrees <- function(ntree) {
mod_rf <- randomForest(stat_cause_descr ~ .,
ntree = ntree,
data = data_train)
p_rf <- predict(mod_rf,
newdata = data_test,
type = "response")
cM <- caret::confusionMatrix(factor(p_rf,
levels = levels(data_test$stat_cause_descr)),
reference = data_test$stat_cause_descr)
accuracy <- cM$overall["Accuracy"]
syst_time <- system.time(randomForest(stat_cause_descr ~ .,
ntree = ntree,
data = data_train))[3]
list(accuracy = accuracy, syst_time = syst_time)
}
vec_ntree <- c(1, 5)
res <- lapply(vec_ntree, FUN = rf_ntrees)
res
res <- sapply(vec_ntree, FUN = rf_ntrees)
res
res
res <- sapply(vec_ntree, FUN = rf_ntrees)
shiny::runApp('D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny')
res
res
# Application fonction ----
vec_ntree <- c(1, 2, 5)
res <- sapply(vec_ntree, FUN = rf_ntrees)
res
class(res)
data.frame(res)
class(data.frame(res))
?randomForest
runApp('D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny')
?validColors
shiny::runApp('D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny')
rm(list = ls())
library (data.table)				# Dataframe plus efficace pour donnees imposantes
library(randomForest)
library(ggplot2)
# Importation des donnees ----
fires <- fread(
"D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny/data/fires.csv",
header = TRUE,
sep = ",",
na.strings = "",
blank.lines.skip = TRUE,
stringsAsFactors = TRUE
)
# Sélection des feux de cause connue pour les années qui nous intéressent ----
fires_selec <-
fires[stat_cause_descr != "Missing/Undefined" &
fire_year %in% c(1995, 2000, 2005, 2010, 2015), ]
fires_selec$fire_year <- factor(fires_selec$fire_year)
fires_selec$stat_cause_descr <- factor(fires_selec$stat_cause_descr)
# Création des tableaux train et test ----
set.seed(123)
train_index <- sample(c(TRUE, FALSE),
nrow(fires_selec),
replace = TRUE,
prob = c(0.8, 0.2))
test_index <- !train_index
data_train <- as.data.table(fires_selec[train_index, c(1:4, 6)])
data_test <- as.data.table(fires_selec[test_index, c(1:4, 6)])
print(object.size(data_train), units = 'Mb')
# Fonction pour random forest selon ntree ----
rf_ntrees <- function(ntree) {
mod_rf <- randomForest(stat_cause_descr ~ .,
ntree = ntree,
data = data_train)
p_rf <- predict(mod_rf,
newdata = data_test,
type = "response")
cM <- caret::confusionMatrix(factor(p_rf,
levels = levels(data_test$stat_cause_descr)),
reference = data_test$stat_cause_descr)
accuracy <- cM$overall["Accuracy"]
syst_time <- system.time(randomForest(stat_cause_descr ~ .,
ntree = ntree,
data = data_train))[3]
list(ntree = ntree, accuracy = accuracy, syst_time = syst_time)
}
# Application fonction ----
vec_ntree <- c(1, 2, 5, 10, 25, 50, 70)
res <- sapply(vec_ntree, FUN = rf_ntrees)
res
res <- as.data.frame(res)
res
# Graphique
ggplot(res) +
geom_line(mapping = aes(x = ntree, y = accuracy)) +
theme_minimal()
ggplot(data = res,
aes(x = ntree, y = accuracy)) +
geom_line()  +
geom_point() +
theme_minimal()
res
# Graphique
ggplot(data = res,
aes(x = res$ntree, y = res$accuracy)) +
geom_line()  +
geom_point() +
theme_minimal()
# Graphique
ggplot(data = res,
aes(x = res$ntree, y = accuracy)) +
geom_line()  +
geom_point() +
theme_minimal()
res <- as.data.frame(t(res))
res
# Graphique
ggplot(data = res,
aes(x = res$ntree, y = res$accuracy)) +
geom_line()  +
geom_point() +
theme_minimal()
res
res$ntree
res <- data.frame(t(res))
res
res <- data.frame(t(res))
res <- sapply(vec_ntree, FUN = rf_ntrees)
res <- data.frame(t(res))
res
res2 <- res
# Graphique
ggplot(data = res2,
aes(x = res2$ntree, y = res2$accuracy)) +
geom_line()  +
geom_point() +
theme_minimal()
# Graphique
ggplot(data = res2,
aes(x = ntree, y = accuracy)) +
geom_line()  +
geom_point() +
theme_minimal()
res2
ggplot() +
geom_line(mapping = aes(x = ntree, y = syst_time)) +
theme_minimal()
ggplot(data = res2) +
geom_line(mapping = aes(x = ntree, y = syst_time)) +
theme_minimal()
# 1. type des colonnes
columns_type <- sapply(X = data, FUN = class)
setwd("D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/1_BenoitTHIEURMEL")
data <- read.table("flights14.csv", sep = ",", header = TRUE)
# 1. type des colonnes
columns_type <- sapply(X = data, FUN = class)
columns_type
# 2. moyenne des colonnes integer
apply(X = data[, which(columns_type == "integer")],
MARGIN = 2, FUN = mean)
res2$ntree <- as.numeric(res2$ntree)
res2$accuracy <- as.numeric(res2$accuracy)
res2$syst_time <- as.numeric(res2$syst_time)
res2
# Graphique
ggplot(data = res2,
aes(x = ntree, y = accuracy)) +
geom_line()  +
geom_point() +
theme_minimal()
ggplot(data = res2,
aes(x = ntree, y = syst_time)) +
geom_line()) +
geom_point() +
theme_minimal()
ggplot(data = res2,
aes(x = ntree, y = syst_time)) +
geom_line() +
geom_point() +
theme_minimal()
# Graphique
ggplot(data = res2,
aes(x = ntree, y = accuracy)) +
geom_line()  +
geom_point() +
labs(x = "Nombre d'arbres",
y = "Accuracy",
title = "Optimisation de l'algorithme randomForest") +
theme_minimal()
ggplot(data = res2,
aes(x = ntree, y = syst_time)) +
geom_line() +
geom_point() +
labs(x = "Nombre d'arbres",
y = "Temps de calcul (en secondes)",
title = "Optimisation de l'algorithme randomForest") +
theme_minimal()
?geom_line
# Graphique
ggplot(data = res2,
aes(x = ntree, y = accuracy)) +
geom_line(colour = "#B83A1B")  +
geom_point(colour = "#B83A1B") +
labs(x = "Nombre d'arbres",
y = "Accuracy",
title = "Optimisation de l'algorithme randomForest") +
theme_minimal()
ggplot(data = res2,
aes(x = ntree, y = syst_time)) +
geom_line(colour = "#B83A1B") +
geom_point(colour = "#B83A1B") +
labs(x = "Nombre d'arbres",
y = "Temps de calcul (en secondes)",
title = "Optimisation de l'algorithme randomForest") +
theme_minimal()
write.csv(res_opt_rf,".\\res_opt_rf.csv", row.names = FALSE, col.names = FALSE)
write.csv(res_opt_rf,".\\res_opt_rf.csv", row.names = FALSE)
res_opt_rf <- res2
write.csv(res_opt_rf,".\\res_opt_rf.csv", row.names = FALSE)
# Export pour réutiliser ces données dans l'app Shiny
write.csv(res_opt_rf,".\\res_opt_rf.csv", row.names = FALSE)
# Export pour réutiliser ces données dans l'app Shiny
write.csv(res_opt_rf,".\\res_opt_rf.csv", row.names = FALSE)
# Export pour réutiliser ces données dans l'app Shiny
write.csv(res_opt_rf,".\\res_opt_rf.csv", row.names = FALSE)
getwd
getwd()
# Importation des résultats de la prédiction
res_opt_rf <- read.table("./data/res_opt_rf.csv")
setwd("D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny")
# Importation des résultats de la prédiction
res_opt_rf <- read.table("./data/res_opt_rf.csv")
library(readr)
res_opt_rf <- read_csv("data/res_opt_rf.csv")
View(res_opt_rf)
# Importation des résultats de la prédiction
res_opt_rf <- read.table("data/res_opt_rf.csv")
res_opt_rf
# Importation des résultats de la prédiction
res_opt_rf <- read.csv("data/res_opt_rf.csv")
runApp()
runApp()
# Graphiques Optimisation de l'algorithme randomForest
res_opt_rf_acc <- ggplot(data = res_opt_rf,
aes(x = ntree, y = accuracy)) +
geom_line(colour = "#B83A1B")  + x
res_opt_rf_acc
res_opt_rf
# Graphiques Optimisation de l'algorithme randomForest
res_opt_rf_acc <- ggplot(data = res_opt_rf,
aes(x = ntree, y = accuracy)) +
geom_line(colour = "#B83A1B")  + x
# Graphiques Optimisation de l'algorithme randomForest
res_opt_rf_acc <- ggplot(data = res_opt_rf,
aes(x = ntree, y = accuracy)) +
geom_line(colour = "#B83A1B")  +
geom_point(colour = "#B83A1B") +
labs(x = "Nombre d'arbres",
y = "Accuracy") +
theme_minimal()
runApp()
# Importation des donnees ----
fires <- fread(
"D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny/data/fires.csv",
header = TRUE,
sep = ",",
na.strings = "",
blank.lines.skip = TRUE,
stringsAsFactors = TRUE
)
library (data.table)
library(randomForest)
library(ggplot2)
library(tibble)
library(tidyverse)
# Importation des donnees ----
fires <- fread(
"D:/Google Drive/Agrocampus/M2/UE4-AnalyseDonneesMassiveR/Projet_Foret/AnalyseDonneesMassives_ForestFires/App Shiny/data/fires.csv",
header = TRUE,
sep = ",",
na.strings = "",
blank.lines.skip = TRUE,
stringsAsFactors = TRUE
)
# Sélection des feux de cause connue pour les années qui nous intéressent ----
fires_selec <-
fires[stat_cause_descr != "Missing/Undefined" &
fire_year %in% c(1995, 2000, 2005, 2010, 2015), ]
fires_selec$fire_year <- factor(fires_selec$fire_year)
fires_selec$stat_cause_descr <- factor(fires_selec$stat_cause_descr)
# Création des tableaux train et test ----
set.seed(123)
train_index <- sample(c(TRUE, FALSE),
nrow(fires_selec),
replace = TRUE,
prob = c(0.8, 0.2))
test_index <- !train_index
data_train <- as.data.table(fires_selec[train_index, c(1:4, 6)])
data_test <- as.data.table(fires_selec[test_index, c(1:4, 6)])
print(object.size(data_train), units = 'Mb')
# Avec un seul arbre : rpart ----
mod.CART <- rpart(stat_cause_descr ~ .,
data = data_train)
library(CART)
library(rpart)
# Avec un seul arbre : rpart ----
mod.CART <- rpart::rpart(stat_cause_descr ~ .,
data = data_train)
pred.CART <- predict(mod.CART,
newdata=data_test,
type="class")
cM <- caret::confusionMatrix(factor(pred.CART,levels=levels(data_test$stat_cause_descr)),
reference=data_test$stat_cause_descr)
cM$overall["Accuracy"]
# Graphique
rpart.plot(mod.CART, type = 4)
install.packages("rpart.plot")
library(rpart.plot)
# Graphique
rpart.plot(mod.CART, type = 4)
shiny::runApp()
runApp('E:/Giffard-Pautrel-Zhao/App Shiny')
